{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "# os.listdir('/mnt/c/Users/Mukul/Documents/docker files/ee981')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "kpY0y9YEZ4qQ",
        "outputId": "a76ae148-f86b-44e9-80e0-d95ea549c005"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import  Callback, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Conv2D, concatenate, Input, BatchNormalization, Conv2DTranspose\n",
        "import sklearn as skl\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "# -- TPU code\n",
        "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "# print('Running on TPU ', tpu.cluster_spec().as_dict())\n",
        "\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "# strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "# print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zt4KoHxb51m"
      },
      "source": [
        "# 0.5 - Hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0le8ZHGb_v6"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "TEST_SPLIT = 0.10\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 0.001\n",
        "IMAGE_SIZE = (2160,3840,3) # 3840 or 3480?\n",
        "TARGET_SIZE = (512 ,512,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMlOMGribgVF"
      },
      "source": [
        "# 1 - Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Due to inconsistent documentation it was unclear if the functions were being resolved eagerly or lazily. ~~It was universally reccomended that the tf.function decorator enabled lazy processing though.~~ Using the tf.function decorator caused the kernel to crash.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUGfsxbBZ4qS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# RGB_FIRE_PATH  = '/content/drive/MyDrive/Colab Notebooks/Colab files/EE981/Images/'\n",
        "# MASK_FIRE_PATH = '/content/drive/MyDrive/Colab Notebooks/Colab files/EE981/Masks/'\n",
        "RGB_FIRE_PATH  = '/mnt/c/Users/Mukul/Documents/docker files/ee981/EE981/Images/'\n",
        "MASK_FIRE_PATH = '/mnt/c/Users/Mukul/Documents/docker files/ee981/EE981/Masks/'\n",
        "\n",
        "img_paths = [RGB_FIRE_PATH + 'image_' + str(i) + '.jpg' for i in range(2002)]\n",
        "mask_paths  = [MASK_FIRE_PATH + 'image_' + str(i) + '.png' for i in range(2002)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPxEOWy2lv8r"
      },
      "outputs": [],
      "source": [
        "# @tf.function # Converts following to polymorphic func\n",
        "def get_image(filename):\n",
        "    \"\"\" Lazily reads and resizes images\n",
        "    Args:\n",
        "        filename (str): String path. location of image\n",
        "    Returns:\n",
        "        (tf.tensor , tf.tensor): returns decoded image and masks of size TARGET_SIZE\n",
        "    \"\"\"\n",
        "    img = tf.io.read_file(filename[0])\n",
        "    mask = tf.io.read_file(filename[1])\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    mask = tf.image.decode_png(mask)\n",
        "    img = tf.image.resize(img,(TARGET_SIZE[0],TARGET_SIZE[1]),method ='nearest')\n",
        "    mask = tf.image.resize(mask,(TARGET_SIZE[0],TARGET_SIZE[1]), method = 'nearest')\n",
        "    return (img, mask)\n",
        "\n",
        "# @tf.function\n",
        "def prepare_ds(x, y):\n",
        "    \"\"\" Maps the get_image function to the required img dataset and batches\n",
        "    Args:\n",
        "        x (list(str)): list of img paths\n",
        "        y (list(str)): list of mask paths\n",
        "\n",
        "    Returns:\n",
        "        tf.dataset: batched img dataset\n",
        "    \"\"\"\n",
        "    zipped_paths = list(zip(x,y))\n",
        "    img_dataset = tf.data.Dataset.from_tensor_slices(zipped_paths)\n",
        "    img_dataset = img_dataset.map(get_image)\n",
        "    img_dataset = img_dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    return img_dataset\n",
        "    \n",
        "train_paths_x, tmp_x, train_paths_y, tmp_y  = skl.model_selection.train_test_split(img_paths, mask_paths, test_size=TEST_SPLIT*2) # shuffles\n",
        "test_paths_x, val_paths_x, test_paths_y, val_paths_y  = skl.model_selection.train_test_split(tmp_x, tmp_y, test_size=0.5) # shuffles\n",
        "print(f'length of train: {len(train_paths_x)}, val: {len(val_paths_x)}, test: {len(test_paths_x)}')\n",
        "\n",
        "train_ds = prepare_ds(train_paths_x, train_paths_y)\n",
        "val_ds = prepare_ds(val_paths_x, val_paths_y)\n",
        "test_ds = prepare_ds(test_paths_x, test_paths_y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR6RnVPeZ4qT"
      },
      "source": [
        "# 2 - Constructing the U-Net Architecture\n",
        "\n",
        "## 2.05 - U-Net from FLAME\n",
        "\n",
        "This model is the same one from the FLAME paper. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout, Lambda\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
        "\n",
        "def model_unet_kaggle(input_size=TARGET_SIZE, num_classes=2):\n",
        "    \"\"\"\n",
        "    This function returns a U-Net Model for this binary fire segmentation images:\n",
        "    Arxiv Link for U-Net: https://arxiv.org/abs/1505.04597\n",
        "    :param img_hieght: Image Height\n",
        "    :param img_width: Image Width\n",
        "    :param img_channel: Number of channels in each image\n",
        "    :param num_classes: Number of classes based on the Ground Truth Masks\n",
        "    :return: A convolutional NN based on Tensorflow and Keras\n",
        "    \"\"\"\n",
        "    inputs = Input(input_size)\n",
        "    s = Lambda(lambda x: x / 255)(inputs)\n",
        "\n",
        "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S68vVzh6xmI-"
      },
      "source": [
        "# 3 - Train / Load model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.ops import clip,log\n",
        "\n",
        "class wbce(tf.keras.Loss):\n",
        "    def __init__(self, rate=1e-2):\n",
        "        super().__init__()\n",
        "        self.rate = rate\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return base_config\n",
        "        \n",
        "    def call(self,y_true, y_pred):\n",
        "        \"\"\"This is the custom WBCE function called during eval.\n",
        "        Applies a weight map to the BCE loss.\n",
        "\n",
        "        Args:\n",
        "            y_true: True img\n",
        "            y_pred: Predicted img\n",
        "\n",
        "        Returns:\n",
        "           float64: loss metric\n",
        "        \"\"\"\n",
        "        tf_y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
        "        tf_y_pred = tf.cast(y_pred, dtype=y_pred.dtype)\n",
        "\n",
        "        weights_v = tf.where(tf.equal(tf_y_true, 1),0.90, 0.10)\n",
        "        weights_v = tf.cast(weights_v, dtype=y_pred.dtype)\n",
        "        ce = tf.keras.losses.binary_crossentropy(tf_y_true, tf_y_pred, from_logits=False)\n",
        "        # print(ce,(weights_v))\n",
        "        loss = tf.keras.ops.mean(tf.multiply(ce, tf.squeeze(weights_v)))\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h4Q5E64Z4qU"
      },
      "outputs": [],
      "source": [
        "def train_model():\n",
        "    \"\"\"\n",
        "        Compiles and trains the model using two callbacks\n",
        "        Returns:\n",
        "           Keras.model: trained model object\n",
        "           Keras.History: model training history object      \n",
        "    \"\"\"\n",
        "           \n",
        "    model = model_unet_kaggle()\n",
        "    model.compile(optimizer=tf.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "                    loss=wbce, #'binary_crossentropy',\n",
        "                    metrics=[ tf.keras.metrics.Precision(),\n",
        "                            tf.keras.metrics.Recall(),\n",
        "                            tf.keras.metrics.MeanIoU(2),\n",
        "                            tf.keras.metrics.IoU(num_classes = 2,target_class_ids=[0,1]),\n",
        "                            'accuracy'])\n",
        "    \n",
        "    scheduler = lambda epoch: LEARNING_RATE if epoch<5 else LEARNING_RATE/100\n",
        "    early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
        "    \n",
        "    history = model.fit(train_ds, validation_data= val_ds,\n",
        "                        epochs = EPOCHS,\n",
        "                        callbacks = [\n",
        "                            early_stop,\n",
        "                            tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "                            ]\n",
        "                        )\n",
        "    return model, history\n",
        "\n",
        "def load_model(path):\n",
        "    return tf.keras.models.load_model(path)\n",
        "    \n",
        "# model = load_model(os.path.join('../working_unet_720_720.keras'))\n",
        "model, history = train_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save/Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "def save_model(model, history, name ):\n",
        "    model.save_weights(name + '.weights.h5')\n",
        "    with open(name + '.history','wb') as f:\n",
        "        pickle.dump(history.history,f)\n",
        "\n",
        "def load_model(model_name):\n",
        "    model = model_unet_kaggle()\n",
        "    model.load_weights(model_name + '.weights.h5')#custom_objects={ 'loss':wbce },compile = False)\n",
        "    with open(model_name + '.history', 'rb') as f:\n",
        "        history = pickle.load(f)\n",
        "    return model,history\n",
        "# model,history = load_model('paper_unet_512_512_norm_wbce')\n",
        "# save_model(model,history,'paper_unet_512_512_norm_wbce')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFIYr8erDL0Q"
      },
      "source": [
        "# 4 - Plot and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJt0BMemVGiw"
      },
      "outputs": [],
      "source": [
        "input_img_it =  test_ds\n",
        "\n",
        "# in, gt = ds.take(4)[0]\n",
        "for i in test_ds.take(4):\n",
        "    input_img = i[0]\n",
        "    input_gt = i[1]\n",
        "    \n",
        "mask = model.predict(np.array([input_img[0]]))\n",
        "\n",
        "fig,((ax1,ax2,),(ax3,ax4,)) = plt.subplots(2,2,figsize=(8,8))\n",
        "fig.suptitle('Weighted Binary Cross entropy')\n",
        "\n",
        "ax1.set_title('Input image')\n",
        "ax1.imshow(np.array(input_img[0]).astype(np.uint8))\n",
        "\n",
        "ax2.set_title('Ground truth')\n",
        "ax2.imshow(input_gt[0])\n",
        "print(np.unique(input_gt[0]))\n",
        "ax3.set_title('Model output - No thresh')\n",
        "ax3.imshow(mask[0])\n",
        "\n",
        "ax4.set_title('Thresholded output')\n",
        "threshed_mask = np.where(mask[0] < 0.9, 0, 1)\n",
        "ax4.imshow(threshed_mask)\n",
        "\n",
        "# plt.savefig('weighted_BCE-fig.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -- precision recall\n",
        "\n",
        "p_r_vals = []\n",
        "thresh_vals = range(1,9,1)\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    \"\"\"Calculate recall metrics\n",
        "\n",
        "    Args:\n",
        "      y_true (tf.tensor): ground truth\n",
        "      y_pred (tf.tensor): prediction from model\n",
        "\n",
        "    Returns:\n",
        "        np.float32: recall value\n",
        "    \"\"\"\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    true_positives = tf.keras.ops.sum(y_true * y_pred)\n",
        "    possible_positives = tf.keras.ops.sum(y_true)\n",
        "    recall = true_positives / (possible_positives +tf.keras.backend.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    \"\"\"Calculate precision metrics\n",
        "\n",
        "    Args:\n",
        "      y_true (tf.tensor): ground truth\n",
        "      y_pred (tf.tensor): prediction from model\n",
        "    \n",
        "    Returns:\n",
        "        np.float32: precision value\n",
        "    \"\"\"\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "    true_positives = tf.keras.ops.sum(y_true * y_pred)\n",
        "    all_positives = tf.keras.ops.sum(y_pred)\n",
        "\n",
        "    recall = true_positives / (all_positives +tf.keras.backend.epsilon())\n",
        "    return recall\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Generates precision + recall for different thresholds\n",
        "r_p=[]\n",
        "for thresh in thresh_vals:\n",
        "\n",
        "  threshed_mask = np.where(mask[0] <= thresh/10, 0, 1)\n",
        "  r_p.append((tf.keras.backend.eval(recall_m(input_gt[0],threshed_mask)),\n",
        "  tf.keras.backend.eval(precision_m(input_gt[0],threshed_mask))))\n",
        "  plt.annotate(f'$0.{thresh}$',(r_p[-1][0],r_p[-1][1]))\n",
        "\n",
        "plt.plot(*zip(*r_p))\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall curve')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/Colab files/paper_unet_512_512_norm_wbce.history','rb') as f:\n",
        "#     history = pickle.load(f)\n",
        "# history = history.history\n",
        "print(history.keys())\n",
        "\n",
        "# Unsure why but the subscript next to the metric keeps changing. when generating plots the subscript needs to be changed to match history.history dict\n",
        "plt.figure(figsize=(12,4))\n",
        "ax = plt.subplot(1,2,1)\n",
        "plt.plot(history['recall_1'], color='blue', label = 'train recall')\n",
        "plt.plot(history['val_recall_1'], linestyle='dashed',color='blue',label = 'val recall')\n",
        "ax.set_title('Training vs Validation performance')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('percentage')\n",
        "plt.plot(history['val_precision_1'],  linestyle='dashed',color='orange',label = 'val precision')\n",
        "plt.plot(history['precision_1'],color='orange',label = 'train precision')\n",
        "plt.legend()\n",
        "# plt.set_title('precision')\n",
        "\n",
        "ax = plt.subplot(1,2,2)\n",
        "plt.plot(history['loss'],color= 'blue', label = 'Training loss')\n",
        "plt.plot(history['val_loss'],color = 'orange',label='Validation loss')\n",
        "plt.legend()\n",
        "ax.set_title('weighted binary cross entropy loss')\n",
        "plt.figure()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load and predict video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import  cv2\n",
        "import timeit\n",
        "def process_vid_frame(frame):   \n",
        "    return tf.image.resize(frame,(TARGET_SIZE[0],TARGET_SIZE[1]))\n",
        "\n",
        "vid = cv2.VideoCapture('1-Zenmuse_X4S_1.mp4')\n",
        "width  = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))   # float `width`\n",
        "height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))  # float `height`\n",
        "fps = vid.get(cv2.CAP_PROP_FPS)\n",
        "mask_vid = cv2.VideoWriter(filename='mask.mp4',fourcc=cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "                           fps = fps,frameSize = (512,512),isColor=False) # writes mask video\n",
        "main_vid = cv2.VideoWriter(filename='vid.mp4',fourcc=cv2.VideoWriter_fourcc(*'mp4v'), \n",
        "                           fps = fps,frameSize = (512,512),isColor=True) # outputs the frames selected for processing\n",
        "\n",
        "# Streaming has some overhead\n",
        "i=0\n",
        "m_ar=[]\n",
        "tmp_ar=[]\n",
        "frames_to_skip = 0\n",
        "\n",
        "# This while loop also generates an adaditional video consisting only of  \n",
        "# frames from the input that were used for the prediction (used for the presentation)\n",
        "while (vid.isOpened() and i<5000):\n",
        "    \n",
        "    ret, frame = vid.read()\n",
        "    print(i) if i%100 == 0 else None\n",
        "    \n",
        "    if i % (frames_to_skip + 1) == 0:\n",
        "        \n",
        "        input_img = process_vid_frame(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        mask_prediction = model.predict(input_img[None,...])\n",
        "        mask_prediction = np.where(mask_prediction < 0.3, 0, 255)\n",
        "        m_ar.append(input_img)\n",
        "        tmp_ar.append(mask_prediction)\n",
        "        main_vid.write( tf.keras.backend.eval(input_img)[...,::-1].astype(np.uint8))\n",
        "        mask_vid.write(np.squeeze(mask_prediction).astype(np.uint8))\n",
        "    \n",
        "    i+=1\n",
        "\n",
        "vid.release()\n",
        "mask_vid.release()\n",
        "main_vid.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "EE992",
      "language": "python",
      "name": "ee992"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
